{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09fa6c1-2a40-415f-bbac-3d4878d1b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d115c8a-fd31-4392-9f73-69c441fe93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "def build_cnn_lstm_model():\n",
    "    inputs = tf.keras.Input(shape=(24, 1))  # Shape: (timesteps, features)\n",
    "\n",
    "    # CNN part\n",
    "    x = layers.Conv1D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # LSTM part\n",
    "    x = layers.LSTM(64, return_sequences=True, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = layers.LSTM(128, return_sequences=False, activation=\"relu\")(x)  # Final LSTM layer\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Dense layers\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1)(x)  # Regression output (e.g., BPM)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb34234-e767-4d16-95e1-1fe9f40e2348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## model1 with dataset 1 with haar cascade\n",
    "# model1=build_cnn_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be40b6c3-a95c-4f9f-b61c-96dbac403de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de4828d-c19f-4eca-86ef-059297b5c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=np.load(\"input.npy\")\n",
    "# Y=np.load(\"out.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef358fb-4298-496c-8ec2-7c938bb6e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.compile(optimizer=\"adam\",metrics=[\"mae\"],loss=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8288235-a20f-4134-87b3-fecb2c48243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history1=model1.fit(X,Y,epochs=10,callbacks=callback,validation_split=0.3)\n",
    "# history1=model1.fit(X,Y,epochs=10,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e84bc8c-d40b-45c5-b373-60684a067654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##model 2 same architecture as model1 but with both dataset 1 and 2 and haarcascade\n",
    "# model2=build_cnn_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd286099-e036-4503-a649-ff76181322a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.load(\"input.npy\")\n",
    "Y1=np.load(\"out.npy\")\n",
    "\n",
    "X2=np.load(\"input2.npy\")\n",
    "Y2=np.load(\"out2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3800ada-4fef-4980-964f-1d66e0fec46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.vstack([X1,X2])\n",
    "Y=np.vstack([Y1,Y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab65e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93f7b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
       "        75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
       "       101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "       114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "       127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 140, 141,\n",
       "       143, 145, 147, 148], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b63acf4-e43a-438b-bc5a-2b9d9c581641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.compile(optimizer=\"adam\",metrics=[\"mae\"],loss=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15290b76-1267-482a-82f3-31b3f374dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history2=model2.fit(X,Y,epochs=10,callbacks=callback,validation_split=0.3)\n",
    "# history2=model2.fit(X,Y,epochs=10,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de14f8c-e8e5-4405-b567-56a14a63bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "##New architecture\n",
    "def build_cnn_lstm_model2():\n",
    "    inputs = tf.keras.Input(shape=(24, 1))  # Shape: (timesteps, features)\n",
    "    # CNN part\n",
    "    x = layers.Conv1D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    # LSTM part\n",
    "    x = layers.LSTM(64, return_sequences=True, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.LSTM(128, return_sequences=True, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.LSTM(128, return_sequences=False, activation=\"relu\")(x)  # Final LSTM layer\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # Dense layers\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1)(x)  # Regression output (e.g., BPM)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fcf75bc-3d4b-4f9d-b204-e8a706bef0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##model3 with new architecture and dataset1 using haar cascade\n",
    "# model3=build_cnn_lstm_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb845e04-3f1f-4b4a-abe8-8e5d1a70fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3.compile(optimizer=\"adam\",metrics=[\"mae\"],loss=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60455912-f2a8-4db6-9f23-c6f16de25125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history3=model3.fit(X1,Y1,epochs=10,callbacks=callback,validation_split=0.3)\n",
    "# history3=model3.fit(X,Y,epochs=10,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5b2e87a-e181-4982-9f7e-5adf673b3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##model4 with same architecture as model 3 and both dataset1 and dataset2 using haar cascade\n",
    "# model4=build_cnn_lstm_model2()\n",
    "# model4.compile(optimizer=\"adam\",metrics=[\"mae\"],loss=\"mae\")\n",
    "# # history4=model4.fit(X,Y,epochs=10,callbacks=callback,validation_split=0.3)\n",
    "# history4=model4.fit(X,Y,epochs=10,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b76352b7-a550-4b46-ac61-9ab6f36f9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_cnn_lstm_model3():\n",
    "#     inputs = tf.keras.Input(shape=(24, 1))  # Shape: (timesteps, features)\n",
    "\n",
    "#     # CNN part\n",
    "#     x = layers.Conv1D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "#     x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     x = layers.Conv1D(64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "#     x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     # LSTM part\n",
    "#     x = layers.LSTM(64, return_sequences=True, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = layers.LSTM(128, return_sequences=True, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = layers.LSTM(128, return_sequences=False, activation=\"relu\")(x)  # Final LSTM layer\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     # Dense layers\n",
    "#     x = layers.Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = layers.Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = layers.Dense(512, activation=\"relu\")(x)\n",
    "#     outputs = layers.Dense(1)(x)  # Regression output (e.g., BPM)\n",
    "\n",
    "#     model = tf.keras.Model(inputs, outputs)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef94c413-966d-4eb0-b564-80f6050c15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model 5 with similar architecture using dataset1 and dataset 2 with mediapipe as ROI\n",
    "# model5=build_cnn_lstm_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "811f6920-7bc5-4bad-b989-deae2cc220d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1=np.load(\"input1_media.npy\")\n",
    "# Y1=np.load(\"out1_media.npy\")\n",
    "\n",
    "# X2=np.load(\"input2_media.npy\")\n",
    "# Y2=np.load(\"out2_media.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3cc1618-6eaa-4280-9c3b-af9309246efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=np.vstack([X1,X2])\n",
    "# Y=np.vstack([Y1,Y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baeaebf6-b29a-40f8-bc61-da70251ca3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model5.compile(optimizer=\"adam\",metrics=[\"mae\"],loss=\"mae\")\n",
    "# # history5=model5.fit(X,Y,epochs=10,callbacks=callback,validation_split=0.3)\n",
    "# history5=model5.fit(X,Y,epochs=10,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0724ac0-ed35-4897-9832-327e8810a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #model 6 with similar architecture using dataset1 and dataset 2 with haar cascade as ROI and usign bidrectional lstm and using of residual connection\n",
    "# from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "# from tensorflow.keras.layers import Add\n",
    "\n",
    "# def build_cnn_lstm_model4():\n",
    "#     inputs = tf.keras.Input(shape=(24, 1))  # Shape: (timesteps, features)\n",
    "\n",
    "#     # CNN part\n",
    "#     x = layers.Conv1D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "#     x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     # After first Conv1D and MaxPooling\n",
    "#     shortcut = x\n",
    "#     x = layers.Conv1D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "#     x = Add()([shortcut, x])  # Residual connection\n",
    "\n",
    "#     # LSTM part\n",
    "#     x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, activation=\"tanh\"))(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, activation=\"tanh\"))(x)  # Final LSTM layer\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     # Dense layers\n",
    "#     x = layers.Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = layers.Dense(512, activation=\"relu\")(x)\n",
    "#     outputs = layers.Dense(1)(x)  # Regression output (e.g., BPM)\n",
    "\n",
    "#     model = tf.keras.Model(inputs, outputs)\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "788f835f-42d2-4293-a08e-834132772c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-3,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9\n",
    "# )\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "640d614d-5d3a-40ac-93c0-9e7349d52bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model6=build_cnn_lstm_model4()\n",
    "# model6.compile(optimizer=optimizer, loss='huber', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1734ab2-3515-4265-99e7-169b93001edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1=np.load(\"input1_reshaped.npy\")\n",
    "# Y1=np.load(\"out1_reshaped.npy\")\n",
    "\n",
    "# X2=np.load(\"input2_reshaped.npy\")\n",
    "# Y2=np.load(\"out2_reshaped.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71d4e6df-6156-477b-964a-da8708b04c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=np.vstack([X1,X2])\n",
    "# Y=np.vstack([Y1,Y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab6b17a2-7a0f-4c89-b72e-39112cd27d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history6=model6.fit(X,Y,epochs=10,callbacks=callback,validation_split=0.2)\n",
    "# history6=model6.fit(X,Y,epochs=10,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "684f5c9f-c929-4c05-af0b-3b435bbd155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(history1.history[\"loss\"], c=\"r\",label=\"model1\") \n",
    "# plt.plot(history2.history[\"loss\"], c=\"y\",label=\"model2\")\n",
    "# plt.plot(history3.history[\"loss\"], c=\"g\",label=\"model3\") \n",
    "# plt.plot(history4.history[\"loss\"], c=\"m\",label=\"model4\") \n",
    "# plt.plot(history5.history[\"loss\"], c=\"c\",label=\"model5\") \n",
    "# plt.plot(history6.history[\"loss\"], c=\"b\",label=\"model6\") \n",
    "# plt.plot(history7.history[\"loss\"], c=\"purple\",label=\"model7\") \n",
    "\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Training Loss over Epochs\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "263efe2a-3ce2-44da-b25e-ceb0730cd7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model6.save(\"model6.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e84f24d6-ac77-48b2-961d-9f7d28b8fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "def build_cnn_lstm_model5():\n",
    "    inputs = tf.keras.Input(shape=(24, 1))  # Shape: (timesteps, features)\n",
    "\n",
    "    # LSTM part\n",
    "    x = layers.LSTM(64, return_sequences=True, activation=\"tanh\")(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = layers.LSTM(64, return_sequences=True, activation=\"tanh\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = layers.LSTM(128, return_sequences=False, activation=\"tanh\")(x)  # Final LSTM layer\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Dense layers\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1)(x)  # Regression output (e.g., BPM)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b63f366-9c3e-4ae0-bbcf-2e47b9673d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748869140.227497    1648 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2248 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model7=build_cnn_lstm_model5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a771eadd-80d1-4d4c-b030-1a86d07e46b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748869173.355621    1833 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 68.5707 - mae: 68.5707 - val_loss: 25.9875 - val_mae: 25.9875\n",
      "Epoch 2/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - loss: 18.3859 - mae: 18.3859 - val_loss: 39.2327 - val_mae: 39.2327\n"
     ]
    }
   ],
   "source": [
    "model7.compile(optimizer=\"adam\",metrics=[\"mae\"],loss=\"mae\")\n",
    "history7=model7.fit(X,Y,epochs=10,callbacks=callback,validation_split=0.3)\n",
    "# history7=model7.fit(X,Y,epochs=10,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90422908-722b-43e9-8c35-e1fea9f06c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_cnn_lstm_model8():\n",
    "#     inputs = tf.keras.Input(shape=(24, 1))  # Shape: (timesteps, features)\n",
    "\n",
    "#     # CNN part\n",
    "#     x = layers.Conv1D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "#     x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     x = layers.Conv1D(64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "#     x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "#     # GRU part\n",
    "#     x = layers.GRU(64, return_sequences=True, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = layers.GRU(128, return_sequences=False, activation=\"relu\")(x)  # Final LSTM layer\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     # Dense layers\n",
    "#     x = layers.Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = layers.Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = layers.Dense(512, activation=\"relu\")(x)\n",
    "#     outputs = layers.Dense(1)(x)  # Regression output (e.g., BPM)\n",
    "\n",
    "#     model = tf.keras.Model(inputs, outputs)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df61d27b-5eb6-42bd-a2fe-e61797c379c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8=build_cnn_lstm_model8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fccca820-1a34-4ba2-b40f-84a7b88aa5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748869310.603410    1836 service.cc:148] XLA service 0x7f4137d29ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748869310.603848    1836 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-06-02 13:01:50.950980: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/97\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38:56\u001b[0m 24s/step - loss: 102.6719 - mae: 102.6719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748869324.457569    1836 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 176ms/step - loss: 85.4134 - mae: 85.4134 - val_loss: 52.6813 - val_mae: 52.6813\n",
      "Epoch 2/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 16.1427 - mae: 16.1427 - val_loss: 14.5755 - val_mae: 14.5755\n",
      "Epoch 3/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 15.1349 - mae: 15.1349 - val_loss: 6.8994 - val_mae: 6.8994\n",
      "Epoch 4/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 14.0021 - mae: 14.0021 - val_loss: 7.7702 - val_mae: 7.7702\n"
     ]
    }
   ],
   "source": [
    "model8.compile(optimizer=\"adam\",metrics=[\"mae\"],loss=\"mae\")\n",
    "history8=model8.fit(X,Y,epochs=10,callbacks=callback,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4034015-950a-44de-98ea-5a02be337a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.save(\"model8.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2aa95766-f8ac-4f3a-aaee-cd03c49f4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "model9=load_model(\"bpm_model_hd.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06e8bd53-952c-43d5-b2d7-f19b29aed316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - loss: 14.1274 - mae: 14.1274 - val_loss: 9.9782 - val_mae: 9.9782\n",
      "Epoch 2/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 13.5149 - mae: 13.5149 - val_loss: 6.3351 - val_mae: 6.3351\n",
      "Epoch 3/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 14.1074 - mae: 14.1074 - val_loss: 12.9412 - val_mae: 12.9412\n"
     ]
    }
   ],
   "source": [
    "model9.compile(optimizer=\"adam\",metrics=[\"mae\"],loss=\"mae\")\n",
    "history9=model9.fit(X,Y,epochs=10,callbacks=callback,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798e7df-6eb5-4f4e-9bb5-702f94b3a250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
